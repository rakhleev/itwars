---
layout: post
title:  "Показатель CSAT - верить или нет?"
date:   2020-08-27 17:40:06
categories: Metrika
image: robots.png
description: Почему поддержке ставят пятерки, но не видят в ней пользы? Расследуем оценки пользователей.
tags: CSAT
---
Перед каждым руководителем поддержки стоит вопрос — как понять, что пользователи довольны. Часто используют CSAT — индекс клиентской удовлетворенности. Но иногда метрика показывает высокий уровень счастья, а отзывы о поддержке далеки от восторгов. Почему так происходит и как получить объективную оценку? Рассказываем, как мы искали ответы на эти вопросы для поддержки агрегатора такси.

> Представим, что вы внедрили в поддержке опрос клиентов о качестве обслуживания, посмотрели на цифры и остались довольны. А затем на интервью спросили клиентов об отношении к поддержке. Пазл не сложился, потому что неожиданно результаты CSAT разошлись с реальностью: очно каждый сказал, что специалисты не помогают, да и смысла обращаться в такую поддержку нет. >

На какую метрику тогда опираться? Мы впервые погрузились в проблему, когда один из популярных сервисов такси попросил нас разобраться, почему показатель CSAT выше среднего, а в живом общении, отзывах в соцсетях и на телефонных опросах пользователи говорят о поддержке негативно и разочарованы уровнем помощи. Рассказываем, как нам удалось выяснить, насколько объективную картину позволяет увидеть метрика и нуждается ли она в усовершенствовании.

---

## Часть первая, в которой мы рассказываем, как работали над проектом

Наш проект был похож на расследование. А значит и действовали мы как настоящие детективы — изучали место «преступления» и допрашивали подозреваемых. Но если серьезно, то план был такой: 

 1. Изучить проблему. Погружаемся в процессы, общаемся с командой, читаем отзывы о поддержке в открытых источниках.
2. Проанализировать клиентский опыт, сформулировать гипотезы. На этом этапе исследовали двумя способами — активный (интервью) и пассивный (чтение диалогов с клиентами и гайдов для поддержки, прослушка звонков).
3. Проверить гипотезы.

> Изучение проблемы и анализ клиентского опыта мы начали с того, что оценили по шкале «хорошо/плохо» 2000 диалогов, а также 200 звонков поддержки за последний месяц. Цель оценки — рассмотреть диалоги и звонки с точки зрения решения проблемы так, как это сделал бы клиент — невзирая на внутренние ограничения и условности и опираясь только на удовлетворенность ответом. Затем мы проверили, насколько серьезное расхождение между нашей и пользовательской оценкой.

### Критерии оценки
1. Понимание сути проблемы
2. Внимательность
3. Решение проблемы
4. Грамотность, логика и работа с текстом

> Если хотя бы у одного из четырех пунктов значение отрицательное, то весь диалог автоматически маркируется как плохо отработанный.

Получилось, что из ста человек, обратившихся в поддержку, ответом должны быть довольны не 86 клиентов (как показывали результаты CSAT), а только 76. Так, мы убедились в том, что проблема с точностью метрики существует.

> 10%
> расхождение между оценкой пользователей и Supprt.Science

Затем мы встретились с 14 пользователями, спросили их о болях и отношении к поддержке. Мы задавали им три типа вопросов:

1. проблематика обращений в поддержку;
2. частота обращений;
3. удовлетворенность решением проблемы.

> Интервью позволили выделить главные боли и эмоции, которые эти боли сопровождают. Интересно, что средняя удовлетворенность поддержкой по результатам интервью составила всего 67%.

Завершив активный и пассивный анализ, мы двинулись дальше.

## Часть вторая, в которой мы описываем гипотезы и способы их проверки

###### Гипотеза 1

> CSAT не отражает реальность, так как диалоги без оценок в среднем хуже, чем оцененные

**Идея.** Пользователи не оценивают диалоги с неудовлетворительным ответом. Это мешает увидеть в результатах CSAT реальное отношение.

**Как возникла?** Заметили, что четверть не оцененных пользователями диалогов, получили от нас оценку «плохо». На интервью часть пользователей также упоминали, что не оценивают «те обращения, где мне не помогли».

**Как проверяли?**
1. Определили топ-10 проблемных тематик 
2. Оценили по методике «хорошо/плохо» по 100 диалогов в каждой из тематик 
3. Спрогнозировали удовлетворенность пользователей в неоцененных диалогах 
4. Подсчитали удовлетворенность, если бы пользователи оценили все диалоги 
5. Посмотрели на разницу между реальными и прогнозируемыми оценками пользователей

**Выводы.** Гипотеза не подтвердила, что в ста процентах случаев диалоги без оценок хуже, чем оцененные. Но в двух топовых тематиках корреляция была выражена значительно. То есть в определенных тематиках пользователи склонны не оценивать плохие кейсы, и у этого должны быть свои причины.

###### Гипотеза 2

> В CSAT попадают диалоги, где нет проблемы, и они влияют на средний показатель удовлетворенности

**Идея.** Часть диалогов не содержит в себе проблемы. Они «забивают» статистику и мешают читать результаты метрики.

**Как возникла?** Увидели тематику, где пользователь вынужден обращаться в поддержку, но при этом проблемы у него нет: он просто передает информацию. CSAT внутри тематики равен 96%, что выглядит как аномалия. Подобных тематик может оказаться много, и вместе они сильно искажают результаты CSAT.

**Как проверяли?** 

1. Нашли беспроблемные тематики
2. Посчитали удовлетворенность без них
3. Сравнили получившиеся показатели

**Выводы.** Гипотеза сработала. Если не учитывать в общем CSAT тематики без проблемы, то показатель удовлетворенности падает на 5-6%, что намного ближе к цифре, которую показывают голосовые опросы и глубинные интервью. Значит, если составить подробный список подобных тематик и исключать их из общего процента, показатель удовлетворенности будет отражать реальную ситуацию.

###### Гипотеза 3

> CSAT не отражает реальное отношение, так как пользователь ставит пятерку даже когда недоволен

**Идея.** Пользователь вместо плохой оценки ставит пятерку. Ответом на вопрос «что его мотивирует?» могут быть, например, такие соображения: «мои оценки ничего не значат», «переживаю, что увидят двойку от меня, и вообще больше никогда не помогут», «уважаю чужой труд, пусть даже плохой, поэтому не буду портить настроение тому, кто отвечал». Из-за этого показатель завышается.

**Как возникла?** Заметили, что в 25% случаев пользователь оценивает диалог на 4 или 5, хотя его проблема остается нерешенной.

**Как проверяли?**

1. Определили рандомную выборку пользователей
2. Сделали 100 догоняющих звонков тем, кто оценил работу поддержки, и задали несколько вопросов — о решении последней проблемы и о работе поддержки в целом
3. Сравнили оценки и ответы по телефону

**Выводы.** Из всех респондентов 11% пользователей поставили поддержке хорошую оценку, а на обзвоне изменили ее на плохую. Также интересно, что 15% думают, что оценка может повлиять на отношение к ним. Считаем, что на маленькой выборке мы подтвердили тезис, но оценить влияние на CSAT в цифрах довольно сложно.

###### Гипотеза 4

> Негативные диалоги имеют больший вес, чем обычные, но учитываются в CSAT лишь однажды

**Идея.** Одна плохая коммуникация может сильно испортить впечатление о поддержке, даже если в следующие разы пользователь продолжит ставить пятерки.

**Как возникла?** Гипотеза возникла после общения с пользователями на проблемных интервью.

**Как проверяли?**

1. Выгрузили диалоги за двухмесячный период, в которых минимум одна оценка была отрицательной и минимум две оценки — положительными.
2. Оценили эти диалоги и проследили, существует ли негативное влияние плохого обращения на хорошее.
3. Позвонили пользователям из выборки и спросили об их отношении к поддержке — для сравнения со средним CSAT по прошлым обращениям

**Выводы.** На звонках гипотеза не сработала: отношение к поддержке не зависит от прошлого негативного опыта. Нужно исследовать гипотезу глубже другими методами и сравнивать влияние единицы во времени и единицы в каждой из тематик. Найти закономерность оценки диалога с общим представлением о поддержке.

## Часть третья, в которой мы делаем выводы
✔️
В среднем пользователи одинаково честно оценивают как хорошие, так и плохие диалоги. В определенных тематиках есть вероятность того, что худшие чаты и звонки не получат оценку, но причины этого сервису еще предстоит изучить.

✔️
В беспроблемных тематиках пользователи не ожидают реальной помощи от поддержки, поэтому оценивают такие диалоги в абсолютном большинстве случаев положительно. Это «забивает» статистику.

✔️
Пользователи могут ставить ложноположительные оценки, но их влияние на показатель удовлетворенности неочевидно.

✔️
На малой выборке взаимосвязь между общим впечатлением о поддержке и негативным опытом в прошлом не доказана, но эту гипотезу стоит исследовать глубже.

> Главный вывод: CSAT как инструмент измерения — работает. С помощью этой метрики можно наблюдать отношение пользователей к поддержке. Конечно, важно помнить о существовании погрешностей и стараться уменьшать их влияние. Например, исключать из общей статистики тематики, где нет проблемы для пользователя. А еще лучше — автоматизировать такие вопросы, чтобы клиентам не нужно было даже тратить время на обращение в поддержку.

Но если CSAT работает, то почему пользователи на очных интервью так сильно ругали агентов и говорили, что от них не дождешься помощи? Причина в процессах и накопившемся негативном эффекте от проблемных диалогов. Если клиенты довольно долгое время терпели неудобства, например, сломанную функцию перевода, и не смотря на просьбы службы поддержки, задача остается нерешенной, то для пользователя складывается ощущение, что поддержка работает, но только для решения общих вопросов, но не проблемы в корне. Как системно изменить укоренившиеся отношение к службе поддержки? Мы готовы рассказать. 